{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(csv_file_path, output_save):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and testing sets and saves them as CSV files.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): Path to the input CSV file.\n",
    "        output_save (str): Directory where the split files will be saved.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing X_train, X_test, y_train, y_test.\n",
    "    \"\"\"\n",
    "    csv_file = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Ensure the CSV file has a 'label' column\n",
    "    if 'label' not in csv_file.columns:\n",
    "        raise ValueError(f\"Column 'label' not found in file {csv_file_path}\")\n",
    "\n",
    "    # Drop the 'Image' column if it exists\n",
    "    if 'Image' in csv_file.columns:\n",
    "        csv_file.drop(columns=['Image'], inplace=True)\n",
    "\n",
    "    # Separate features (X) and target (Y)\n",
    "    x_source = csv_file.drop('label', axis='columns')\n",
    "    y_source = csv_file['label']\n",
    "\n",
    "    # Split data into training and testing sets (80:20 ratio)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_source, y_source, test_size=0.2, random_state=123)\n",
    "\n",
    "    # Map labels: 'abnormal' -> 1, 'normal' -> 0\n",
    "    y_train = y_train.replace({'abnormal': 1, 'normal': 0})\n",
    "    y_test = y_test.replace({'abnormal': 1, 'normal': 0})\n",
    "\n",
    "    # Combine and save training and testing data\n",
    "    df_train = pd.concat([x_train, y_train], axis=1)\n",
    "    df_test = pd.concat([x_test, y_test], axis=1)\n",
    "\n",
    "    df_train.to_csv(os.path.join(output_save, 'train.csv'), index=False)\n",
    "    df_test.to_csv(os.path.join(output_save, 'test.csv'), index=False)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_grid():\n",
    "    \"\"\"\n",
    "    Generates a random grid for hyperparameter tuning.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing hyperparameter options for tuning.\n",
    "    \"\"\"\n",
    "    random_grid = {\n",
    "        'learning_rate': np.arange(0.01, 0.2, 0.01),\n",
    "        'min_child_weight': np.arange(0, 5, 1),\n",
    "        'min_split_loss': np.arange(0, 5, 1),\n",
    "        'max_depth': np.arange(3, 10, 1),\n",
    "        'reg_lambda': [2]\n",
    "    }\n",
    "\n",
    "    return random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(cv, verbose, n_jobs, random_grid, x_train, y_train, output_save):\n",
    "    \"\"\"\n",
    "    Performs grid search to find the best XGBoost model and saves it.\n",
    "\n",
    "    Args:\n",
    "        cv (int): Number of cross-validation folds.\n",
    "        verbose (int): Verbosity level for grid search.\n",
    "        n_jobs (int): Number of parallel jobs to run.\n",
    "        random_grid (dict): Hyperparameter grid for tuning.\n",
    "        x_train (DataFrame): Training features.\n",
    "        y_train (Series): Training labels.\n",
    "        output_save (str): Directory where the best model will be saved.\n",
    "\n",
    "    Returns:\n",
    "        XGBClassifier: The best XGBoost model.\n",
    "    \"\"\"\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    xgb_grid_search = GridSearchCV(\n",
    "        xgb_model,\n",
    "        random_grid,\n",
    "        cv=cv,\n",
    "        verbose=verbose,\n",
    "        n_jobs=n_jobs,\n",
    "        scoring='accuracy')\n",
    "\n",
    "    xgb_grid_search.fit(x_train, y_train)\n",
    "\n",
    "    best_model = xgb_grid_search.best_estimator_\n",
    "\n",
    "    filename = f'{output_save}/xgb_best'\n",
    "    pickle.dump(best_model, open(filename, 'wb'))\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_data(best_model, x_train, y_train, x_test, y_test, y_predict, output_save):\n",
    "    \"\"\"\n",
    "    Generates final data including performance metrics, feature importance, and saves visualizations.\n",
    "\n",
    "    Args:\n",
    "        best_model (XGBClassifier): The trained model.\n",
    "        x_train (DataFrame): Training features.\n",
    "        y_train (Series): Training labels.\n",
    "        x_test (DataFrame): Testing features.\n",
    "        y_test (Series): Testing labels.\n",
    "        y_predict (array): Predicted labels for the test set.\n",
    "        output_save (str): Directory where results and visualizations will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Save best parameters\n",
    "    best_params_df = pd.DataFrame([best_model.get_params()])\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    # Create DataFrame for performance metrics\n",
    "    performance_metrics = {\n",
    "        'Metric': ['Accuracy', 'Precision', 'Specificity', 'Recall', 'F1 Score'],\n",
    "        'Value': [accuracy, precision, specificity, recall, f1]\n",
    "    }\n",
    "    df_performance = pd.DataFrame(performance_metrics)\n",
    "\n",
    "    # Calculate feature importances\n",
    "    feature_importances = best_model.feature_importances_\n",
    "    features_df = pd.DataFrame({\n",
    "        'Feature': x_test.columns.tolist(),\n",
    "        'Importance': feature_importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Calculate train vs test accuracy\n",
    "    train_accuracy = best_model.score(x_train, y_train)\n",
    "    test_accuracy = best_model.score(x_test, y_test)\n",
    "    train_test_accuracy = {\n",
    "        'Dataset': ['Train Accuracy', 'Test Accuracy'],\n",
    "        'Accuracy': [train_accuracy, test_accuracy]\n",
    "    }\n",
    "    df_train_test_accuracy = pd.DataFrame(train_test_accuracy)\n",
    "\n",
    "    # Save train vs test accuracy\n",
    "    df_train_test_accuracy.to_csv(os.path.join(output_save, 'test_train_accuracy.csv'), index=False)\n",
    "\n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', ax=axes[0],\n",
    "                xticklabels=['Normal', 'Abnormal'],\n",
    "                yticklabels=['Normal', 'Abnormal'])\n",
    "    axes[0].set_xlabel('Predicted Labels')\n",
    "    axes[0].set_ylabel('True Labels')\n",
    "    axes[0].set_title('Confusion Matrix')\n",
    "\n",
    "    ax = sns.barplot(x='Metric', y='Value', data=df_performance, palette='Blues_d', ax=axes[1])\n",
    "    axes[1].set_title('Performance Metrics')\n",
    "    axes[1].set_ylabel('Value')\n",
    "    axes[1].set_ylim(0, 1)\n",
    "\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height():.2f}',\n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='center',\n",
    "                    xytext=(0, 9), textcoords='offset points')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_save}/confusion_matrix_and_performance_metrics.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Save CSV files\n",
    "    best_params_df.to_csv(os.path.join(output_save, 'model_best_params.csv'), index=False)\n",
    "    features_df.to_csv(os.path.join(output_save, 'features_ranking.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../percobaan/YUV_LBP_GLRLM_TAMURA\"\n",
    "csv_file = \"../percobaan/YUV_LBP_GLRLM_TAMURA/color_moment_lbp_glrlm_tamura.csv\"\n",
    "\n",
    "# os.makedirs(folder_path, os.path.basename(csv_file)[:-4])\n",
    "# output_path = os.path.join(folder_path, os.path.basename(csv_file)[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3325 candidates, totalling 16625 fits\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = split_data(csv_file, folder_path)\n",
    "random_grid = get_random_grid()\n",
    "best_model = get_best_model(cv=5, verbose=3, random_grid=random_grid, n_jobs=5, x_train=x_train, y_train=y_train, output_save=folder_path)\n",
    "y_predict = best_model.predict(x_test)\n",
    "get_final_data(best_model, x_train, y_train, x_test, y_test, y_predict, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Feature  Importance\n",
      "0            std    0.179594\n",
      "1      SRE_deg45    0.113255\n",
      "2   LRHGLE_deg90    0.101264\n",
      "3         mean_u    0.092040\n",
      "4       Contrast    0.088824\n",
      "5    LGLRE_deg90    0.082138\n",
      "6     LRE_deg135    0.063749\n",
      "7     LGLRE_deg0    0.059286\n",
      "8      RLN_deg90    0.058725\n",
      "9    LRHGLE_deg0    0.057631\n",
      "10         std_v    0.053269\n",
      "11      SRE_deg0    0.050227\n"
     ]
    }
   ],
   "source": [
    "# Features Ranking\n",
    "features_ranking = pd.read_csv(\"../percobaan/YUV_LBP_GLRLM_TAMURA/features_ranking.csv\").query('Importance != 0')\n",
    "print(features_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              std\n",
      "1        SRE_deg45\n",
      "2     LRHGLE_deg90\n",
      "3           mean_u\n",
      "4         Contrast\n",
      "5      LGLRE_deg90\n",
      "6       LRE_deg135\n",
      "7       LGLRE_deg0\n",
      "8        RLN_deg90\n",
      "9      LRHGLE_deg0\n",
      "10           std_v\n",
      "11        SRE_deg0\n",
      "Name: Feature, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(features_ranking['Feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_select = x_train[['mean_u', 'std_v', 'std', 'SRE_deg0', 'SRE_deg45', 'LRE_deg135', 'RLN_deg90', 'LGLRE_deg0', 'LGLRE_deg90', 'LRHGLE_deg0', 'LRHGLE_deg90', 'Contrast']]\n",
    "x_test_select = x_test[['mean_u', 'std_v', 'std', 'SRE_deg0', 'SRE_deg45', 'LRE_deg135', 'RLN_deg90', 'LGLRE_deg0', 'LGLRE_deg90', 'LRHGLE_deg0', 'LRHGLE_deg90', 'Contrast']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3325 candidates, totalling 16625 fits\n"
     ]
    }
   ],
   "source": [
    "best_model_select = get_best_model(cv=5, verbose=3, random_grid=random_grid, n_jobs=5, x_train=x_train_select, y_train=y_train, output_save=\"../percobaan/YUV_LBP_GLRLM_TAMURA/select\")\n",
    "y_predict_select = best_model_select.predict(x_test_select)\n",
    "get_final_data(best_model_select, x_train_select, y_train, x_test_select, y_test, y_predict_select, \"../percobaan/YUV_LBP_GLRLM_TAMURA/select\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pengolahan_citra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
